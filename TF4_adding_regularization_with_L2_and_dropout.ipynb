{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        inputs\n",
    "    )\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        x\n",
    "    )\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(\n",
    "        128, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01),)(\n",
    "        x\n",
    "    )\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "782/782 - 14s - loss: 3.0766 - accuracy: 0.3602\n",
      "Epoch 2/150\n",
      "782/782 - 7s - loss: 1.9338 - accuracy: 0.4815\n",
      "Epoch 3/150\n",
      "782/782 - 7s - loss: 1.6344 - accuracy: 0.5241\n",
      "Epoch 4/150\n",
      "782/782 - 7s - loss: 1.5033 - accuracy: 0.5512\n",
      "Epoch 5/150\n",
      "782/782 - 7s - loss: 1.4345 - accuracy: 0.5662\n",
      "Epoch 6/150\n",
      "782/782 - 7s - loss: 1.3919 - accuracy: 0.5806\n",
      "Epoch 7/150\n",
      "782/782 - 7s - loss: 1.3540 - accuracy: 0.5910\n",
      "Epoch 8/150\n",
      "782/782 - 8s - loss: 1.3273 - accuracy: 0.6007\n",
      "Epoch 9/150\n",
      "782/782 - 7s - loss: 1.3118 - accuracy: 0.6095\n",
      "Epoch 10/150\n",
      "782/782 - 7s - loss: 1.2883 - accuracy: 0.6191\n",
      "Epoch 11/150\n",
      "782/782 - 7s - loss: 1.2726 - accuracy: 0.6253\n",
      "Epoch 12/150\n",
      "782/782 - 7s - loss: 1.2608 - accuracy: 0.6297\n",
      "Epoch 13/150\n",
      "782/782 - 7s - loss: 1.2472 - accuracy: 0.6369\n",
      "Epoch 14/150\n",
      "782/782 - 7s - loss: 1.2373 - accuracy: 0.6398\n",
      "Epoch 15/150\n",
      "782/782 - 7s - loss: 1.2240 - accuracy: 0.6470\n",
      "Epoch 16/150\n",
      "782/782 - 7s - loss: 1.2071 - accuracy: 0.6515\n",
      "Epoch 17/150\n",
      "782/782 - 7s - loss: 1.1997 - accuracy: 0.6580\n",
      "Epoch 18/150\n",
      "782/782 - 7s - loss: 1.1907 - accuracy: 0.6609\n",
      "Epoch 19/150\n",
      "782/782 - 7s - loss: 1.1871 - accuracy: 0.6651\n",
      "Epoch 20/150\n",
      "782/782 - 7s - loss: 1.1802 - accuracy: 0.6653\n",
      "Epoch 21/150\n",
      "782/782 - 7s - loss: 1.1738 - accuracy: 0.6716\n",
      "Epoch 22/150\n",
      "782/782 - 7s - loss: 1.1599 - accuracy: 0.6784\n",
      "Epoch 23/150\n",
      "782/782 - 7s - loss: 1.1558 - accuracy: 0.6832\n",
      "Epoch 24/150\n",
      "782/782 - 7s - loss: 1.1401 - accuracy: 0.6859\n",
      "Epoch 25/150\n",
      "782/782 - 7s - loss: 1.1339 - accuracy: 0.6886\n",
      "Epoch 26/150\n",
      "782/782 - 8s - loss: 1.1359 - accuracy: 0.6915\n",
      "Epoch 27/150\n",
      "782/782 - 8s - loss: 1.1245 - accuracy: 0.6933\n",
      "Epoch 28/150\n",
      "782/782 - 7s - loss: 1.1206 - accuracy: 0.6971\n",
      "Epoch 29/150\n",
      "782/782 - 7s - loss: 1.1139 - accuracy: 0.6998\n",
      "Epoch 30/150\n",
      "782/782 - 7s - loss: 1.1025 - accuracy: 0.7037\n",
      "Epoch 31/150\n",
      "782/782 - 8s - loss: 1.0981 - accuracy: 0.7048\n",
      "Epoch 32/150\n",
      "782/782 - 8s - loss: 1.0961 - accuracy: 0.7108\n",
      "Epoch 33/150\n",
      "782/782 - 7s - loss: 1.0929 - accuracy: 0.7102\n",
      "Epoch 34/150\n",
      "782/782 - 7s - loss: 1.0855 - accuracy: 0.7122\n",
      "Epoch 35/150\n",
      "782/782 - 7s - loss: 1.0822 - accuracy: 0.7163\n",
      "Epoch 36/150\n",
      "782/782 - 7s - loss: 1.0775 - accuracy: 0.7168\n",
      "Epoch 37/150\n",
      "782/782 - 7s - loss: 1.0745 - accuracy: 0.7201\n",
      "Epoch 38/150\n",
      "782/782 - 7s - loss: 1.0702 - accuracy: 0.7221\n",
      "Epoch 39/150\n",
      "782/782 - 7s - loss: 1.0660 - accuracy: 0.7235\n",
      "Epoch 40/150\n",
      "782/782 - 7s - loss: 1.0576 - accuracy: 0.7278\n",
      "Epoch 41/150\n",
      "782/782 - 7s - loss: 1.0531 - accuracy: 0.7305\n",
      "Epoch 42/150\n",
      "782/782 - 8s - loss: 1.0589 - accuracy: 0.7279\n",
      "Epoch 43/150\n",
      "782/782 - 7s - loss: 1.0468 - accuracy: 0.7317\n",
      "Epoch 44/150\n",
      "782/782 - 7s - loss: 1.0374 - accuracy: 0.7361\n",
      "Epoch 45/150\n",
      "782/782 - 7s - loss: 1.0414 - accuracy: 0.7349\n",
      "Epoch 46/150\n",
      "782/782 - 7s - loss: 1.0390 - accuracy: 0.7360\n",
      "Epoch 47/150\n",
      "782/782 - 7s - loss: 1.0295 - accuracy: 0.7374\n",
      "Epoch 48/150\n",
      "782/782 - 7s - loss: 1.0218 - accuracy: 0.7437\n",
      "Epoch 49/150\n",
      "782/782 - 7s - loss: 1.0223 - accuracy: 0.7440\n",
      "Epoch 50/150\n",
      "782/782 - 7s - loss: 1.0165 - accuracy: 0.7482\n",
      "Epoch 51/150\n",
      "782/782 - 8s - loss: 1.0224 - accuracy: 0.7439\n",
      "Epoch 52/150\n",
      "782/782 - 8s - loss: 1.0140 - accuracy: 0.7481\n",
      "Epoch 53/150\n",
      "782/782 - 7s - loss: 1.0173 - accuracy: 0.7472\n",
      "Epoch 54/150\n",
      "782/782 - 7s - loss: 1.0076 - accuracy: 0.7521\n",
      "Epoch 55/150\n",
      "782/782 - 7s - loss: 1.0026 - accuracy: 0.7539\n",
      "Epoch 56/150\n",
      "782/782 - 7s - loss: 1.0049 - accuracy: 0.7524\n",
      "Epoch 57/150\n",
      "782/782 - 7s - loss: 1.0002 - accuracy: 0.7561\n",
      "Epoch 58/150\n",
      "782/782 - 8s - loss: 0.9968 - accuracy: 0.7547\n",
      "Epoch 59/150\n",
      "782/782 - 7s - loss: 0.9920 - accuracy: 0.7571\n",
      "Epoch 60/150\n",
      "782/782 - 7s - loss: 0.9858 - accuracy: 0.7586\n",
      "Epoch 61/150\n",
      "782/782 - 7s - loss: 0.9897 - accuracy: 0.7587\n",
      "Epoch 62/150\n",
      "782/782 - 7s - loss: 0.9885 - accuracy: 0.7584\n",
      "Epoch 63/150\n",
      "782/782 - 7s - loss: 0.9849 - accuracy: 0.7595\n",
      "Epoch 64/150\n",
      "782/782 - 7s - loss: 0.9902 - accuracy: 0.7611\n",
      "Epoch 65/150\n",
      "782/782 - 7s - loss: 0.9765 - accuracy: 0.7640\n",
      "Epoch 66/150\n",
      "782/782 - 7s - loss: 0.9794 - accuracy: 0.7649\n",
      "Epoch 67/150\n",
      "782/782 - 7s - loss: 0.9802 - accuracy: 0.7646\n",
      "Epoch 68/150\n",
      "782/782 - 7s - loss: 0.9719 - accuracy: 0.7673\n",
      "Epoch 69/150\n",
      "782/782 - 7s - loss: 0.9714 - accuracy: 0.7687\n",
      "Epoch 70/150\n",
      "782/782 - 7s - loss: 0.9659 - accuracy: 0.7696\n",
      "Epoch 71/150\n",
      "782/782 - 7s - loss: 0.9791 - accuracy: 0.7686\n",
      "Epoch 72/150\n",
      "782/782 - 7s - loss: 0.9644 - accuracy: 0.7714\n",
      "Epoch 73/150\n",
      "782/782 - 7s - loss: 0.9715 - accuracy: 0.7706\n",
      "Epoch 74/150\n",
      "782/782 - 7s - loss: 0.9674 - accuracy: 0.7722\n",
      "Epoch 75/150\n",
      "782/782 - 7s - loss: 0.9619 - accuracy: 0.7725\n",
      "Epoch 76/150\n",
      "782/782 - 7s - loss: 0.9617 - accuracy: 0.7728\n",
      "Epoch 77/150\n",
      "782/782 - 7s - loss: 0.9639 - accuracy: 0.7738\n",
      "Epoch 78/150\n",
      "782/782 - 7s - loss: 0.9614 - accuracy: 0.7737\n",
      "Epoch 79/150\n",
      "782/782 - 8s - loss: 0.9586 - accuracy: 0.7763\n",
      "Epoch 80/150\n",
      "782/782 - 7s - loss: 0.9593 - accuracy: 0.7756\n",
      "Epoch 81/150\n",
      "782/782 - 7s - loss: 0.9503 - accuracy: 0.7783\n",
      "Epoch 82/150\n",
      "782/782 - 7s - loss: 0.9544 - accuracy: 0.7779\n",
      "Epoch 83/150\n",
      "782/782 - 7s - loss: 0.9475 - accuracy: 0.7799\n",
      "Epoch 84/150\n",
      "782/782 - 8s - loss: 0.9558 - accuracy: 0.7778\n",
      "Epoch 85/150\n",
      "782/782 - 7s - loss: 0.9528 - accuracy: 0.7805\n",
      "Epoch 86/150\n",
      "782/782 - 7s - loss: 0.9575 - accuracy: 0.7780\n",
      "Epoch 87/150\n",
      "782/782 - 7s - loss: 0.9441 - accuracy: 0.7838\n",
      "Epoch 88/150\n",
      "782/782 - 8s - loss: 0.9410 - accuracy: 0.7828\n",
      "Epoch 89/150\n",
      "782/782 - 8s - loss: 0.9467 - accuracy: 0.7820\n",
      "Epoch 90/150\n",
      "782/782 - 8s - loss: 0.9429 - accuracy: 0.7854\n",
      "Epoch 91/150\n",
      "782/782 - 8s - loss: 0.9421 - accuracy: 0.7851\n",
      "Epoch 92/150\n",
      "782/782 - 7s - loss: 0.9355 - accuracy: 0.7873\n",
      "Epoch 93/150\n",
      "782/782 - 7s - loss: 0.9352 - accuracy: 0.7864\n",
      "Epoch 94/150\n",
      "782/782 - 7s - loss: 0.9479 - accuracy: 0.7827\n",
      "Epoch 95/150\n",
      "782/782 - 7s - loss: 0.9357 - accuracy: 0.7857\n",
      "Epoch 96/150\n",
      "782/782 - 7s - loss: 0.9392 - accuracy: 0.7875\n",
      "Epoch 97/150\n",
      "782/782 - 7s - loss: 0.9452 - accuracy: 0.7856\n",
      "Epoch 98/150\n",
      "782/782 - 7s - loss: 0.9323 - accuracy: 0.7892\n",
      "Epoch 99/150\n",
      "782/782 - 7s - loss: 0.9342 - accuracy: 0.7877\n",
      "Epoch 100/150\n",
      "782/782 - 7s - loss: 0.9355 - accuracy: 0.7884\n",
      "Epoch 101/150\n",
      "782/782 - 8s - loss: 0.9345 - accuracy: 0.7859\n",
      "Epoch 102/150\n",
      "782/782 - 8s - loss: 0.9347 - accuracy: 0.7883\n",
      "Epoch 103/150\n",
      "782/782 - 7s - loss: 0.9308 - accuracy: 0.7907\n",
      "Epoch 104/150\n",
      "782/782 - 7s - loss: 0.9351 - accuracy: 0.7911\n",
      "Epoch 105/150\n",
      "782/782 - 8s - loss: 0.9314 - accuracy: 0.7918\n",
      "Epoch 106/150\n",
      "782/782 - 9s - loss: 0.9289 - accuracy: 0.7906\n",
      "Epoch 107/150\n",
      "782/782 - 9s - loss: 0.9269 - accuracy: 0.7924\n",
      "Epoch 108/150\n",
      "782/782 - 9s - loss: 0.9367 - accuracy: 0.7894\n",
      "Epoch 109/150\n",
      "782/782 - 8s - loss: 0.9257 - accuracy: 0.7945\n",
      "Epoch 110/150\n",
      "782/782 - 8s - loss: 0.9272 - accuracy: 0.7941\n",
      "Epoch 111/150\n",
      "782/782 - 8s - loss: 0.9253 - accuracy: 0.7931\n",
      "Epoch 112/150\n",
      "782/782 - 8s - loss: 0.9241 - accuracy: 0.7935\n",
      "Epoch 113/150\n",
      "782/782 - 8s - loss: 0.9264 - accuracy: 0.7939\n",
      "Epoch 114/150\n",
      "782/782 - 8s - loss: 0.9163 - accuracy: 0.7977\n",
      "Epoch 115/150\n",
      "782/782 - 8s - loss: 0.9259 - accuracy: 0.7950\n",
      "Epoch 116/150\n",
      "782/782 - 8s - loss: 0.9285 - accuracy: 0.7908\n",
      "Epoch 117/150\n",
      "782/782 - 9s - loss: 0.9257 - accuracy: 0.7939\n",
      "Epoch 118/150\n",
      "782/782 - 8s - loss: 0.9209 - accuracy: 0.7969\n",
      "Epoch 119/150\n",
      "782/782 - 8s - loss: 0.9178 - accuracy: 0.7971\n",
      "Epoch 120/150\n",
      "782/782 - 8s - loss: 0.9236 - accuracy: 0.7956\n",
      "Epoch 121/150\n",
      "782/782 - 8s - loss: 0.9231 - accuracy: 0.7964\n",
      "Epoch 122/150\n",
      "782/782 - 8s - loss: 0.9222 - accuracy: 0.7970\n",
      "Epoch 123/150\n",
      "782/782 - 9s - loss: 0.9124 - accuracy: 0.8001\n",
      "Epoch 124/150\n",
      "782/782 - 7s - loss: 0.9163 - accuracy: 0.8010\n",
      "Epoch 125/150\n",
      "782/782 - 7s - loss: 0.9204 - accuracy: 0.8006\n",
      "Epoch 126/150\n",
      "782/782 - 7s - loss: 0.9098 - accuracy: 0.8010\n",
      "Epoch 127/150\n",
      "782/782 - 8s - loss: 0.9156 - accuracy: 0.7969\n",
      "Epoch 128/150\n",
      "782/782 - 8s - loss: 0.9103 - accuracy: 0.8004\n",
      "Epoch 129/150\n",
      "782/782 - 8s - loss: 0.9189 - accuracy: 0.7988\n",
      "Epoch 130/150\n",
      "782/782 - 7s - loss: 0.9226 - accuracy: 0.7972\n",
      "Epoch 131/150\n",
      "782/782 - 8s - loss: 0.9086 - accuracy: 0.8033\n",
      "Epoch 132/150\n",
      "782/782 - 10s - loss: 0.9069 - accuracy: 0.8018\n",
      "Epoch 133/150\n",
      "782/782 - 7s - loss: 0.9127 - accuracy: 0.8037\n",
      "Epoch 134/150\n",
      "782/782 - 8s - loss: 0.9113 - accuracy: 0.8022\n",
      "Epoch 135/150\n",
      "782/782 - 9s - loss: 0.9166 - accuracy: 0.8000\n",
      "Epoch 136/150\n",
      "782/782 - 10s - loss: 0.9080 - accuracy: 0.8019\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.9160 - accuracy: 0.7999\n",
      "Epoch 138/150\n",
      "782/782 - 8s - loss: 0.9104 - accuracy: 0.8040\n",
      "Epoch 139/150\n",
      "782/782 - 8s - loss: 0.8990 - accuracy: 0.8075\n",
      "Epoch 140/150\n",
      "782/782 - 7s - loss: 0.9120 - accuracy: 0.8021\n",
      "Epoch 141/150\n",
      "782/782 - 8s - loss: 0.9046 - accuracy: 0.8051\n",
      "Epoch 142/150\n",
      "782/782 - 8s - loss: 0.9068 - accuracy: 0.8045\n",
      "Epoch 143/150\n",
      "782/782 - 8s - loss: 0.8998 - accuracy: 0.8074\n",
      "Epoch 144/150\n",
      "782/782 - 8s - loss: 0.9129 - accuracy: 0.8020\n",
      "Epoch 145/150\n",
      "782/782 - 8s - loss: 0.9093 - accuracy: 0.8046\n",
      "Epoch 146/150\n",
      "782/782 - 8s - loss: 0.9032 - accuracy: 0.8060\n",
      "Epoch 147/150\n",
      "782/782 - 8s - loss: 0.9004 - accuracy: 0.8055\n",
      "Epoch 148/150\n",
      "782/782 - 8s - loss: 0.9013 - accuracy: 0.8060\n",
      "Epoch 149/150\n",
      "782/782 - 8s - loss: 0.8974 - accuracy: 0.8082\n",
      "Epoch 150/150\n",
      "782/782 - 8s - loss: 0.9031 - accuracy: 0.8077\n",
      "157/157 - 1s - loss: 1.0947 - accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.094673752784729, 0.7608000040054321]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
