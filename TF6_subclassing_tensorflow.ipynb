{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x=self.conv(input_tensor)\n",
    "        x=self.bn(x, training=training)\n",
    "        x=tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "model=keras.Sequential([CNNBlock(32),\n",
    "                        CNNBlock(64),\n",
    "                        CNNBlock(128),\n",
    "                        layers.Flatten(),\n",
    "                        layers.Dense(10)\n",
    "])\n",
    "\n",
    "class ResBlock():\n",
    "    def __init__(self,channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.cnn1=CNNBlock(channels[0])\n",
    "        self.cnn1=CNNBlock(channels[1])\n",
    "        self.cnn1=CNNBlock(channels[2])\n",
    "        self.pooling=layers.MaxPooling2D()\n",
    "        self.identity_mapping= layers.Conv2D(channels[1],1,padding='same')\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x=self.cnn1(input_tensor, training=training)\n",
    "        x=self.cnn1(x, training=training)\n",
    "        x=self.cnn3(x+self.identity_mapping(input_tensor), training=training)\n",
    "        return self.pooling(x)\n",
    "    \n",
    "class ResNet_Like(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_Like, self).__init__()\n",
    "        self.block1=ResBlock([32,32,64])\n",
    "        self.block2=ResBlock([128,128,256])\n",
    "        self.block3=ResBlock([128,256,512])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 - 31s - loss: 0.6177 - accuracy: 0.9430\n",
      "Epoch 2/3\n",
      "938/938 - 25s - loss: 0.0996 - accuracy: 0.9808\n",
      "Epoch 3/3\n",
      "938/938 - 25s - loss: 0.0389 - accuracy: 0.9884\n",
      "157/157 - 2s - loss: 0.0557 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05566613748669624, 0.9853000044822693]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'],)\n",
    "model.fit(x_train,y_train, batch_size=64,epochs=3,verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubClassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So first we create the CNNBlock using conv, batch, relu, cuz \n",
    "#we want to reuse it \n",
    "\n",
    "#Then we use the ResBlock that uses these blocks multiple times \n",
    "#and also a pooling layer multiple times\n",
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [CNNBlock(32), CNNBlock(64), CNNBlock(128), layers.Flatten(), layers.Dense(10),]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By now we may have noted,e every layer has a init and a \n",
    "#call method\n",
    "#Further we'll see theres also a model method. We can assume this \n",
    "#is how the structure goes for subclassing and its predefined\n",
    "\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.cnn1 = CNNBlock(channels[0], 3)\n",
    "        self.cnn2 = CNNBlock(channels[1], 3)\n",
    "        self.cnn3 = CNNBlock(channels[2], 3)\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.cnn1(input_tensor, training=training)\n",
    "        x = self.cnn2(x, training=training)\n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
    "        x = self.pooling(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Like(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_Like, self).__init__()\n",
    "        self.block1 = ResBlock([32, 32, 64])\n",
    "        self.block2 = ResBlock([128, 128, 256])\n",
    "        self.block3 = ResBlock([128, 256, 512])\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.block1(input_tensor, training=training)\n",
    "        x = self.block2(x, training=training)\n",
    "        x = self.block3(x, training=training)\n",
    "        x = self.pool(x, training=training)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(28, 28, 1))\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_Like().model()\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[2].output\n",
    "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
    "model = keras.Model(base_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 37s - loss: 0.1054 - accuracy: 0.9686\n",
      "157/157 - 2s - loss: 0.0305 - accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as cnn_block_6_layer_call_fn, cnn_block_6_layer_call_and_return_conditional_losses, cnn_block_7_layer_call_fn, cnn_block_7_layer_call_and_return_conditional_losses, cnn_block_8_layer_call_fn while saving (showing 5 of 70). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as cnn_block_6_layer_call_fn, cnn_block_6_layer_call_and_return_conditional_losses, cnn_block_7_layer_call_fn, cnn_block_7_layer_call_and_return_conditional_losses, cnn_block_8_layer_call_fn while saving (showing 5 of 70). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
    "model.save(\"pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
